{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d5cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "from kafka import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d7bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "          #  labels\n",
    "           'class',\n",
    "          #  low-level features\n",
    "           'lepton_1_pT',\n",
    "           'lepton_1_eta',\n",
    "           'lepton_1_phi',\n",
    "           'lepton_2_pT',\n",
    "           'lepton_2_eta',\n",
    "           'lepton_2_phi',\n",
    "           'missing_energy_magnitude',\n",
    "           'missing_energy_phi',\n",
    "          #  high-level derived features\n",
    "           'MET_rel',\n",
    "           'axial_MET',\n",
    "           'M_R',\n",
    "           'M_TR_2',\n",
    "           'R',\n",
    "           'MT2',\n",
    "           'S_R',\n",
    "           'M_Delta_R',\n",
    "           'dPhi_r_b',\n",
    "           'cos(theta_r1)'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60314afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>lepton_1_pT</th>\n",
       "      <th>lepton_1_eta</th>\n",
       "      <th>lepton_1_phi</th>\n",
       "      <th>lepton_2_pT</th>\n",
       "      <th>lepton_2_eta</th>\n",
       "      <th>lepton_2_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>MET_rel</th>\n",
       "      <th>axial_MET</th>\n",
       "      <th>M_R</th>\n",
       "      <th>M_TR_2</th>\n",
       "      <th>R</th>\n",
       "      <th>MT2</th>\n",
       "      <th>S_R</th>\n",
       "      <th>M_Delta_R</th>\n",
       "      <th>dPhi_r_b</th>\n",
       "      <th>cos(theta_r1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972861</td>\n",
       "      <td>0.653855</td>\n",
       "      <td>1.176225</td>\n",
       "      <td>1.157156</td>\n",
       "      <td>-1.739873</td>\n",
       "      <td>-0.874309</td>\n",
       "      <td>0.567765</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-0.252552</td>\n",
       "      <td>1.921887</td>\n",
       "      <td>0.889637</td>\n",
       "      <td>0.410772</td>\n",
       "      <td>1.145621</td>\n",
       "      <td>1.932632</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>1.367815</td>\n",
       "      <td>0.040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667973</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>-1.225171</td>\n",
       "      <td>0.506102</td>\n",
       "      <td>-0.338939</td>\n",
       "      <td>1.672543</td>\n",
       "      <td>3.475464</td>\n",
       "      <td>-1.219136</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>3.775174</td>\n",
       "      <td>1.045977</td>\n",
       "      <td>0.568051</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448410</td>\n",
       "      <td>0.205356</td>\n",
       "      <td>1.321893</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444840</td>\n",
       "      <td>-0.134298</td>\n",
       "      <td>-0.709972</td>\n",
       "      <td>0.451719</td>\n",
       "      <td>-1.613871</td>\n",
       "      <td>-0.768661</td>\n",
       "      <td>1.219918</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>1.831248</td>\n",
       "      <td>-0.431385</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>0.941514</td>\n",
       "      <td>1.587535</td>\n",
       "      <td>2.024308</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>1.562374</td>\n",
       "      <td>1.135454</td>\n",
       "      <td>0.180910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381256</td>\n",
       "      <td>-0.976145</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.448959</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>-0.677328</td>\n",
       "      <td>2.033060</td>\n",
       "      <td>1.533041</td>\n",
       "      <td>3.046260</td>\n",
       "      <td>-1.005285</td>\n",
       "      <td>0.569386</td>\n",
       "      <td>1.015211</td>\n",
       "      <td>1.582217</td>\n",
       "      <td>1.551914</td>\n",
       "      <td>0.761215</td>\n",
       "      <td>1.715464</td>\n",
       "      <td>1.492257</td>\n",
       "      <td>0.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309996</td>\n",
       "      <td>-0.690089</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>1.589283</td>\n",
       "      <td>-0.693326</td>\n",
       "      <td>0.622907</td>\n",
       "      <td>1.087562</td>\n",
       "      <td>-0.381742</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>1.365479</td>\n",
       "      <td>1.179295</td>\n",
       "      <td>0.968218</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083158</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>1.154854</td>\n",
       "      <td>0.094859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  lepton_1_pT  lepton_1_eta  lepton_1_phi  lepton_2_pT  lepton_2_eta  \\\n",
       "0    0.0     0.972861      0.653855      1.176225     1.157156     -1.739873   \n",
       "1    1.0     1.667973      0.064191     -1.225171     0.506102     -0.338939   \n",
       "2    1.0     0.444840     -0.134298     -0.709972     0.451719     -1.613871   \n",
       "3    1.0     0.381256     -0.976145      0.693152     0.448959      0.891753   \n",
       "4    1.0     1.309996     -0.690089     -0.676259     1.589283     -0.693326   \n",
       "\n",
       "   lepton_2_phi  missing_energy_magnitude  missing_energy_phi   MET_rel  \\\n",
       "0     -0.874309                  0.567765           -0.175000  0.810061   \n",
       "1      1.672543                  3.475464           -1.219136  0.012955   \n",
       "2     -0.768661                  1.219918            0.504026  1.831248   \n",
       "3     -0.677328                  2.033060            1.533041  3.046260   \n",
       "4      0.622907                  1.087562           -0.381742  0.589204   \n",
       "\n",
       "   axial_MET       M_R    M_TR_2         R       MT2       S_R  M_Delta_R  \\\n",
       "0  -0.252552  1.921887  0.889637  0.410772  1.145621  1.932632   0.994464   \n",
       "1   3.775174  1.045977  0.568051  0.481928  0.000000  0.448410   0.205356   \n",
       "2  -0.431385  0.526283  0.941514  1.587535  2.024308  0.603498   1.562374   \n",
       "3  -1.005285  0.569386  1.015211  1.582217  1.551914  0.761215   1.715464   \n",
       "4   1.365479  1.179295  0.968218  0.728563  0.000000  1.083158   0.043429   \n",
       "\n",
       "   dPhi_r_b  cos(theta_r1)  \n",
       "0  1.367815       0.040714  \n",
       "1  1.321893       0.377584  \n",
       "2  1.135454       0.180910  \n",
       "3  1.492257       0.090719  \n",
       "4  1.154854       0.094859  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "susy_iterator = pd.read_csv('data/SUSY.csv.gz', header=None, names=COLUMNS, chunksize=100000)\n",
    "susy_df = next(susy_iterator)\n",
    "susy_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d1a3edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       float64\n",
       "lepton_1_pT                 float64\n",
       "lepton_1_eta                float64\n",
       "lepton_1_phi                float64\n",
       "lepton_2_pT                 float64\n",
       "lepton_2_eta                float64\n",
       "lepton_2_phi                float64\n",
       "missing_energy_magnitude    float64\n",
       "missing_energy_phi          float64\n",
       "MET_rel                     float64\n",
       "axial_MET                   float64\n",
       "M_R                         float64\n",
       "M_TR_2                      float64\n",
       "R                           float64\n",
       "MT2                         float64\n",
       "S_R                         float64\n",
       "M_Delta_R                   float64\n",
       "dPhi_r_b                    float64\n",
       "cos(theta_r1)               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "susy_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8640468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  60000\n",
      "Number of testing sample:  40000\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(susy_df, test_size=0.4, shuffle=True)\n",
    "print(\"Number of training samples: \",len(train_df))\n",
    "print(\"Number of testing sample: \",len(test_df))\n",
    "\n",
    "x_train_df = train_df.drop([\"class\"], axis=1)\n",
    "y_train_df = train_df[\"class\"]\n",
    "\n",
    "x_test_df = test_df.drop([\"class\"], axis=1)\n",
    "y_test_df = test_df[\"class\"]\n",
    "\n",
    "x_train = list(filter(None, x_train_df.to_csv(index=False).split(\"\\n\")[1:]))\n",
    "y_train=list(y_train_df)\n",
    "\n",
    "x_test = list(filter(None, x_test_df.to_csv(index=False).split(\"\\n\")[1:]))\n",
    "y_test=list(y_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b32b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "# The labels are set as the kafka message keys so as to store data\n",
    "# in multiple-partitions. Thus, enabling efficient data retrieval\n",
    "# using the consumer groups.\n",
    "x_train = list(filter(None, x_train_df.to_csv(index=False).split(\"\\n\")[1:]))\n",
    "y_train = list(filter(None, y_train_df.to_csv(index=False).split(\"\\n\")[1:]))\n",
    "\n",
    "x_test = list(filter(None, x_test_df.to_csv(index=False).split(\"\\n\")[1:]))\n",
    "y_test = list(filter(None, y_test_df.to_csv(index=False).split(\"\\n\")[1:]))\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cee7d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6721988320350647,0.34237948060035706,-0.7238044142723083,1.1103098392486572,-1.213679790496826,-0.26380720734596247,1.0992820262908936,-1.6995762586593628,1.6501561403274536,-0.32735818624496454,1.028388261795044,1.1920721530914307,1.0286331176757812,2.507549524307251,0.9912425875663757,1.8863195180892944,0.8003770112991333,0.0872780978679657\\r'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2ec9301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26324fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efdcb0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 40000, 40000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_COLUMNS = len(x_train_df.columns)\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2dcad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 60000 messages into topic: susy-train\n",
      "Wrote 40000 messages into topic: susy-test\n"
     ]
    }
   ],
   "source": [
    "def error_callback(exc):\n",
    "    raise Exception('Error while sendig data to kafka: {0}'.format(str(exc)))\n",
    "\n",
    "def write_to_kafka(topic_name, items):\n",
    "  count=0\n",
    "  producer = KafkaProducer(bootstrap_servers=['127.0.0.1:9092'])\n",
    "  for message, key in items:\n",
    "    producer.send(topic_name, key=str(key).encode('utf-8'), value=str(message).encode('utf-8')).add_errback(error_callback)\n",
    "    count+=1\n",
    "  producer.flush()\n",
    "  print(\"Wrote {0} messages into topic: {1}\".format(count, topic_name))\n",
    "\n",
    "write_to_kafka(\"susy-train\", zip(x_train, y_train))\n",
    "write_to_kafka(\"susy-test\", zip(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72efa769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "def decode_kafka_item(item):\n",
    "    message = tf.io.decode_csv(item.message, [[0.0] for i in range(NUM_COLUMNS)])\n",
    "    key = tf.strings.to_number(item.key)\n",
    "    print(type(message))\n",
    "    print(type(key))\n",
    "    return (message, key)\n",
    "\n",
    "BATCH_SIZE=64\n",
    "SHUFFLE_BUFFER_SIZE=64\n",
    "train_ds = tfio.IODataset.from_kafka('susy-train', partition=0, offset=0)\n",
    "train_ds = train_ds.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "train_ds = train_ds.map(decode_kafka_item)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1515aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "\n",
    "OPTIMIZER=\"adam\"\n",
    "LOSS=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "METRICS=['accuracy']\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d8a4e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128)               2432      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,481\n",
      "Trainable params: 68,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# design/build the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(NUM_COLUMNS,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e919479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=list(map(float,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a885d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_x=[]\n",
    "for x in x_train:\n",
    "    x=x[:-1]\n",
    "    x_arr=x.split(',')\n",
    "    x_train_x.append(list(map(float,x_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7dea6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_x=[]\n",
    "for x in x_test:\n",
    "    x=x[:-1]\n",
    "    x_arr=x.split(',')\n",
    "    x_test_x.append(list(map(float,x_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "306a5f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 18), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Add labels to the training data\n",
    "# Preprocess the packet_data to convert string to meaningful value and use here\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_x, y_train))\n",
    "# Set the batch size\n",
    "train_ds = train_ds.shuffle(5000).batch(32)\n",
    "print(train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40252d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 18), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test_x, y_test))\n",
    "# Set the batch size\n",
    "test_ds = test_ds.shuffle(5000).batch(32)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d8696a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.5061 - accuracy: 0.7642\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4692 - accuracy: 0.7819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e41da201f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### PROGRAM WILL RUN SUCCESSFULLY TILL HERE. TO USE IN THE MODEL DO THE PREPROCESSING OF PACKET DATA AS EXPLAINED ### \n",
    "\n",
    "# Have defined some simple model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fe2bfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "test_ds = tfio.experimental.streaming.KafkaGroupIODataset(\n",
    "    topics=[\"susy-test\"],\n",
    "    group_id=\"testcg\",\n",
    "    servers=\"127.0.0.1:9092\",\n",
    "    stream_timeout=10000,\n",
    "    configuration=[\n",
    "        \"session.timeout.ms=7000\",\n",
    "        \"max.poll.interval.ms=8000\",\n",
    "        \"auto.offset.reset=earliest\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "def decode_kafka_test_item(raw_message, raw_key):\n",
    "    message = tf.io.decode_csv(raw_message, [[0.0] for i in range(NUM_COLUMNS)])\n",
    "    key = tf.strings.to_number(raw_key)\n",
    "    print(type(message))\n",
    "    print(type(key))\n",
    "    return (message, key)\n",
    "\n",
    "test_ds = test_ds.map(decode_kafka_test_item)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6605a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 2ms/step - loss: 0.4638 - accuracy: 0.7851\n",
      "test loss, test acc: [0.4637937843799591, 0.785099983215332]\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(test_ds)\n",
    "print(\"test loss, test acc:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbcb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIkernel",
   "language": "python",
   "name": "aikernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
